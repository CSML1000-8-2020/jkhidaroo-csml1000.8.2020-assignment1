---
title: "ANN-model"
author: "Feng"
date: "14/02/2020"
output:
  slidy_presentation: default
  ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
  
## 4. D) Data Modeling - Neural Network

### Universal approximation theorem states that simple ariticial neural networks with only one hidden layer has the potentail to represent almost any contineous functions with nicely assigned parameters and a proper non-polymonial activation function such as signoid or rectified linear unit. 
### R has a package nnet, which can be used for Classification and Regression. We decided to model the data with a simple ANN.

```{r}
# load the package "nnet" which provide the ANN modeling functionality
library("nnet")
```
## preprocess the data for modeling
```{r}
# load the data into a data frame
library('readr')
diagnosis_data_full = read.csv("./input/diagnosis_data.csv")

# set up the function for data normalization
normalize <- function(x) {return ((x - min(x)) / (max(x) - min(x)))}

# normalize the numeric data from column 3 to column 32
maxmindf <- as.data.frame(lapply(diagnosis_data_full[3:32], normalize))

# normalize the factor column, transform M -> -1 and B -> 1

# set up the mapping function to use
myMapper <- function(x) { if(x=="M") {temp <- -1} else {temp <- 1}; return (temp) }

# load the libary "purrr" for the function map
library("purrr")

# pull out column #2 which is the factor column for prediction and transform/normalize it.
factors <- diagnosis_data_full[2:2]
factors$c2 <- unlist(map(diagnosis_data_full$diagnosis, myMapper))
nfactors <- as.data.frame(lapply(factors[2:2], normalize))

# combine the normalized input and output columns into one data frame 
cleanData <- cbind(nfactors, maxmindf)

# split the data into trainset and testset
trainset <- cleanData[1:426,]
testset <- cleanData[427:569,]
```

## Data modeling with the cleaned and normalized data set

```{r}
# set the seed with nice prime number, so make the training re-producible
set.seed(887)
# we use 5 neurons in the hidden layer
fit_net<-nnet(c2~.,data=trainset,size=5, decay=5e-4, maxit=2000)
fit_net
```

## 5. D) Model evaluation

```{r}
# put the predicted values and original values into one single data frame
predictions <- data.frame(cbind(round(predict(fit_net, testset),digits=0), testset$c2))
# add a column "d", to represent the difference with the predicted and the actual
predictions$d <- (predictions$X1 - predictions$X2)
head(predictions,n=5)
# compute the confusionMatrix
table(predictions$X1,predictions$X2)
```

