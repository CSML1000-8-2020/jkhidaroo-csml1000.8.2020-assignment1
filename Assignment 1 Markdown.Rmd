---
title: "Tarun Assignment 1"
author: "tarun bagga"
date: "2/15/2020"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load Liabraries

```{r}
library(ranger)
library(caret)
library(data.table)
library(dplyr)
library(caTools)

```

## 1. Business Understanding

- Objective: The Objective of this project is to create a model from the Wisconsin Breast Cancer Data that would allow for a classification prediction of 'B' or 'M' (Benign or Malignant) when given results from tumor measurement studies.

- Project Plan:

- Business Success Criteria: A successful project outcome would be achieved if a model is created that can predict the 'B' or 'M' outcome with a high degree of accuracy.

- Ethical Framework Questions: 
  - How could your system negatively impact individuals? The greatest negative impact would occur for a false positive diagnosis since this could delay treatment and in a life threatening scenario. A false negative would also be negatively impactful but to a lessor degree.
  - Who is most vulnerable and why? The most vulnerable would be patients with a 'M' dianosis not detectable by the model.
  - How much error in predictions can your business accept for this use case? False positives need to be minimised as much as posible. Minimsing False negatives are second in priority.
  - Will you need to explain which input factors had the greatest influence on outputs? Yes. Being able to explain which features have the most influence on outcome is very desirable.
  - Do you need PII or can you provide group-level data? The analysis requires patient level data however any PII can be anonymised

## 2. Data Understanding

- Ethical Framework Questions: 
  - Have you de-identified your data and taken measures to reduce the probability of reidentification? The data is de-identified.
  - Will socially sensitive features like gender or ethnic background influence outputs? No demographic data is present.
  - Are seemingly harmless features like location hiding proxies for socially sensitive features? No demographic data is present. 

#### Get Data File

- The Dataset used is obtained from: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data


```{r}
# Get dir of opened R file. (Note: Only works for RStudio)
# wdir <- dirname(rstudioapi::getActiveDocumentContext()$path)
# Use relative path instead
wdir <- "."
# show(wdir)

# Concatenate data file subdir and name.
breastcancer_data <- read.csv("data.csv")
```

## 3 Description of the Data
```{r}
str(breastcancer_data)
```

## See the Data
```{r}
show(breastcancer_data)
```

# 4. C) Data Modeling - Logistic Regression

#Data Exploration

```{r}
head(breastcancer_data,6)
summary(breastcancer_data)
names(breastcancer_data)
```

# summarize the class distribution

```{r}
percentage <- prop.table(table(breastcancer_data$diagnosis)) * 100
cbind(freq=table(breastcancer_data$diagnosis), percentage=percentage)
```
## Looking at Missing Values - checking for missing values in all the features. Seems to be issues in inly one colum X. This column either needs to be imputer or removed.
```{r}
sapply(breastcancer_data,function(x) sum(is.na(x)))
```
```{r}
library(Amelia)
```

## Missing values vs observed, Look at the plot for missing versus observed
```{r}

missmap(breastcancer_data, main = "Missing values vs observed")
```

#remove id and x
Now we can removed unwanted features and relabel the target featire as binary 0,1
```{r}
target <- ifelse(breastcancer_data$diagnosis=="B", 1, 0)
target
model_1 = select (breastcancer_data,-c(X,id,diagnosis))
nobs <- nrow(model_1)
nobs
model_1
```
##Scaling Of Data - Since all the features have different scales we need to  makes ure we model features in same scale
```{r}
model_2=scale(model_1)
```

##Summarize the reults if adding the target back to data

```{r}
model_3<-data.frame(cbind(model_2,target))
summary(model_3)
```


## 5 Model Creation
```{r}
set.seed(123)
split = sample.split(model_3$target, SplitRatio = 0.80)
train_data = subset(model_3, split == TRUE)
test_data = subset(model_3, split == FALSE)

Logistic_Model <- glm(target ~ .,data=train_data, family = binomial)
summary(Logistic_Model)
predictTrain = predict(Logistic_Model, type="response")
summary(predictTrain)
```

##This is bad prediction so we need to pick features
We Look at sapply to select features
```{r}
sapply(breastcancer_data, sd)
```
We run the model again with select features
```{r}
Logistic_Model <- glm(target ~ perimeter_mean + perimeter_worst + texture_mean + area_mean + perimeter_se + radius_mean + radius_worst + area_se + texture_worst + area_worst ,data=train_data, family = binomial)
summary(Logistic_Model)
predictTrain = predict(Logistic_Model, type="response")
summary(predictTrain)
```
## Train the model
```{r}
tapply(predictTrain, train_data$target, mean)
table(train_data$target, predictTrain > 0.5)
#install.packages("ROCR")
library(ROCR)
ROCRpred = prediction(predictTrain, train_data$target)
ROCRperf = performance(ROCRpred, "tpr", "fpr")
```

## Including Plots

```{r  echo=FALSE}
plot(ROCRperf)
plot(ROCRperf, colorize=TRUE)
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
```


Prediction

```{r}
predictTest = predict(Logistic_Model, type = "response", newdata = test_data)

```

##Summary of prediction
```{r}
summary(predictTest)
```
##Assessing the predictive ability of the model
In the steps above, we briefly evaluated the fitting of the model, now we would like to see how the model is doing when predicting y on a new set of data. By setting the parameter type='response', R will output probabilities in the form of P(y=1|X). Our decision boundary will be 0.5. If P(y=1|X) > 0.5 then y = 1 otherwise y=0. Note that for some applications different thresholds could be a better option

```{r}
predictTest <- ifelse(predictTest > 0.5,1,0)

misClasificError <- mean(predictTest != test_data$target)
print(paste('Accuracy',1-misClasificError))
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
